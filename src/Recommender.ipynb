{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ville/uni/SHProject/venv/lib64/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/ville/uni/SHProject/venv/lib64/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/ville/uni/SHProject/venv/lib64/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/ville/uni/SHProject/venv/lib64/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/ville/uni/SHProject/venv/lib64/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/ville/uni/SHProject/venv/lib64/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/ville/uni/SHProject/venv/lib64/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/ville/uni/SHProject/venv/lib64/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/ville/uni/SHProject/venv/lib64/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/ville/uni/SHProject/venv/lib64/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/ville/uni/SHProject/venv/lib64/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/ville/uni/SHProject/venv/lib64/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from scipy.sparse import coo_matrix\n",
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "from mlxtend.frequent_patterns import apriori\n",
    "from mlxtend.frequent_patterns import association_rules\n",
    "\n",
    "import wals\n",
    "import model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use these variables to choose which dataset to use, and whether to use saved variables\n",
    "development_dataset = False\n",
    "retrain_model = False\n",
    "recalculate_topn = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_map, item_map, train_sparse, test_sparse, unique_items, unique_users = None, None, None, None, None, None\n",
    "if retrain_model:\n",
    "    clean_start_time = datetime.datetime.now()\n",
    "    if development_dataset:\n",
    "        user_map, item_map, train_sparse, test_sparse, unique_items, unique_users = model.clean_data(\"../data/ml_100k/ratings.csv\")\n",
    "    else:\n",
    "        user_map, item_map, train_sparse, test_sparse, unique_items, unique_users = model.clean_data(\"../data/ml-20m/ratings.csv\")\n",
    "    clean_end_time = datetime.datetime.now()\n",
    "    print(\"Data cleaning duration: \" + str(clean_end_time - clean_start_time))\n",
    "    \n",
    "    latent_factors = 14\n",
    "    num_iters = 20\n",
    "    \n",
    "    train_start_time = datetime.datetime.now()\n",
    "    output_row, output_col = model.train_model(train_sparse, latent_factors, num_iters)\n",
    "    train_end_time = datetime.datetime.now()\n",
    "    print(\"Training duration: \" + str(train_end_time - train_start_time))\n",
    "    model.save_model(development_dataset, user_map, item_map, unique_items, unique_users, output_row, output_col)\n",
    "\n",
    "    train_rmse = wals.get_rmse(output_row, output_col, train_sparse)\n",
    "    test_rmse = wals.get_rmse(output_row, output_col, test_sparse)\n",
    "    print('Train: ' + str(train_rmse) + ', Test: ' + str(test_rmse))\n",
    "else:\n",
    "    user_map, item_map, unique_items, unique_users, output_row, output_col = model.load_saved_model(development_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "138493, 50\n",
      "Prediction duration: 0:00:00.003350\n"
     ]
    }
   ],
   "source": [
    "# This cell is just for testing...\n",
    "user = 18\n",
    "user_rated = [item_map[i] for i, x in enumerate(user_map) if x == user]\n",
    "# print(user_rated)\n",
    "print(str(output_row.shape[0]) + \", \" + str(len(user_rated)))\n",
    "\n",
    "pred_start_time = datetime.datetime.now()\n",
    "model.generate_recommendations(user, user_rated, output_row, output_col, 6)\n",
    "pred_end_time = datetime.datetime.now()\n",
    "print(\"Prediction duration: \" + str(pred_end_time - pred_start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "138493\n",
      "[0 0 0 ... 138492 138492 138492]\n",
      "0\n",
      "20000\n",
      "40000\n",
      "60000\n",
      "80000\n",
      "100000\n",
      "120000\n",
      "Top N calculation duration: 0:09:49.195773\n",
      "length: 138491\n"
     ]
    }
   ],
   "source": [
    "topn_recommendations = []\n",
    "print(str(len(unique_users)))\n",
    "print(user_map)\n",
    "\n",
    "if recalculate_topn:\n",
    "    # Generate top-n...\n",
    "    topn_start_time = datetime.datetime.now()\n",
    "    for k, u in enumerate(unique_users):\n",
    "        user_rated = True#[item_map[i] for i, x in enumerate(user_map) if x == u] #TODO fix\n",
    "        if (k % 20000 == 0):\n",
    "            print(k)\n",
    "        if u < user_map[-1]:\n",
    "            topn_recommendations.append(model.generate_recommendations(u, [], output_row, output_col, 6))\n",
    "    topn_end_time = datetime.datetime.now()\n",
    "    print(\"Top N calculation duration: \" + str(topn_end_time - topn_start_time))\n",
    "    print(\"length: \" + str(len(topn_recommendations)))\n",
    "    if development_dataset:\n",
    "        with open(\"topn_100k.pickle\", \"wb+\") as fp:\n",
    "            pickle.dump(topn_recommendations, fp)\n",
    "    else:\n",
    "        with open(\"topn_20m.pickle\", \"wb+\") as fp:\n",
    "            pickle.dump(topn_recommendations, fp)\n",
    "else:    \n",
    "    # ...or read them from a file...\n",
    "    if development_dataset:\n",
    "        with open(\"topn_20m.pickle\", \"rb\") as fp:\n",
    "            topn_recommendations = pickle.load(fp)\n",
    "    else:\n",
    "        with open(\"topn_20m.pickle\", \"rb\") as fp:\n",
    "            topn_recommendations = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "te = TransactionEncoder()\n",
    "te_ary = te.fit(topn_recommendations).transform(topn_recommendations)\n",
    "topn_df = pd.DataFrame(te_ary, columns=te.columns_)\n",
    "\n",
    "frequent_itemsets = apriori(topn_df, min_support=0.05)\n",
    "frequent_itemsets['length'] = frequent_itemsets['itemsets'].apply(lambda x: len(x))\n",
    "\n",
    "# frequent_itemsets[(frequent_itemsets['length'] == 2)]\n",
    "rules = association_rules(frequent_itemsets)\n",
    "\n",
    "rules = rules[(rules['support'] > 0.05) &\n",
    "      (rules['confidence'] > 0.2) &\n",
    "      (rules['lift'] > 3.0)]\n",
    "\n",
    "# print(rules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10000\n",
      "20000\n",
      "30000\n",
      "40000\n",
      "50000\n",
      "60000\n",
      "70000\n",
      "80000\n",
      "90000\n",
      "100000\n",
      "110000\n",
      "120000\n",
      "130000\n",
      "Top N calculation duration: 0:14:15.420208\n"
     ]
    }
   ],
   "source": [
    "# This generates the explainable recommendations for a list of top N recommendations\n",
    "\n",
    "explainableRecommendations = []\n",
    "exp_start_time = datetime.datetime.now()\n",
    "for i, u in enumerate(unique_users):\n",
    "    recommendations = []\n",
    "    if u < user_map[-1]:\n",
    "        for index, row in rules.iterrows():\n",
    "            antecedents = list(row['antecedents'])\n",
    "            consequents = list(row['consequents'])\n",
    "            if all(x in user_rated for x in antecedents) and all(x not in user_rated for x in consequents):\n",
    "                recommendations.append({\"explanation\": tuple(row['antecedents']), \"recommendation\": tuple(row['consequents'])})\n",
    "    explainableRecommendations.append(recommendations)\n",
    "    if (i % 10000 == 0):\n",
    "        print(i)\n",
    "exp_end_time = datetime.datetime.now()\n",
    "print(\"Top N calculation duration: \" + str(exp_end_time - exp_start_time))\n",
    "    \n",
    "if development_dataset:\n",
    "    with open(\"explainable_100k.pickle\", \"wb+\") as fp:\n",
    "        pickle.dump(explainableRecommendations, fp)\n",
    "else:\n",
    "    with open(\"explainable_20m.pickle\", \"wb+\") as fp:\n",
    "        pickle.dump(explainableRecommendations, fp)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
