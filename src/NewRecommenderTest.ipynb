{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext Cython\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import pickle\n",
    "from surprise import SVD\n",
    "from surprise import Dataset\n",
    "from surprise import Reader\n",
    "from surprise import accuracy\n",
    "from surprise.model_selection import train_test_split\n",
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "from mlxtend.frequent_patterns import apriori\n",
    "from mlxtend.frequent_patterns import association_rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from recommender_algo.editable_svd import EditableSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "development_set = False\n",
    "retrain_model = False\n",
    "recalculate_topn = True\n",
    "recalculate_association_rules = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if retrain_model:\n",
    "    if development_set:\n",
    "        filename = \"../data/ml_100k/ratings.csv\"\n",
    "    else:\n",
    "        filename = \"../data/ml-25m/ratings.csv\"\n",
    "    ratings_df = pd.read_csv(filename, dtype={\n",
    "        'userId': np.int32,\n",
    "        'movieId': np.int32,\n",
    "        'rating': np.float32,\n",
    "        'timestamp': np.int32,\n",
    "    })\n",
    "\n",
    "    reader = Reader(rating_scale=(1, 5))\n",
    "    data = Dataset.load_from_df(ratings_df[['userId', 'movieId', 'rating']], reader)\n",
    "\n",
    "    trainset, testset = train_test_split(data, test_size=.25, random_state=42)\n",
    "    algo = EditableSVD(n_factors=10)\n",
    "\n",
    "    train_start_time = datetime.datetime.now()\n",
    "    algo.fit(trainset)\n",
    "    train_end_time = datetime.datetime.now()\n",
    "    print(\"Training duration: \" + str(train_end_time - train_start_time))\n",
    "    \n",
    "    predictions = algo.test(testset)\n",
    "    accuracy.rmse(predictions)\n",
    "    print(accuracy)\n",
    "    \n",
    "    if development_set:\n",
    "        with open(\"algo-100k.pickle\", \"wb+\") as fp:\n",
    "            pickle.dump(algo, fp)\n",
    "    else:\n",
    "        with open(\"algo-25m.pickle\", \"wb+\") as fp:\n",
    "            pickle.dump(algo, fp)\n",
    "else:\n",
    "    if development_set:\n",
    "        with open(\"algo-100k.pickle\", \"rb\") as fp:\n",
    "            algo = pickle.load(fp)\n",
    "    else:\n",
    "        with open(\"algo-25m.pickle\", \"rb\") as fp:\n",
    "            algo = pickle.load(fp)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: 2020-02-25 15:49:39.805675\n",
      "100: 2020-02-25 15:50:28.562455\n",
      "1000: 2020-02-25 15:58:08.804340\n",
      "2000: 2020-02-25 16:06:42.183617\n",
      "3000: 2020-02-25 16:16:40.254445\n",
      "4000: 2020-02-25 16:25:34.792893\n",
      "5000: 2020-02-25 16:35:04.617478\n",
      "6000: 2020-02-25 16:48:05.280548\n",
      "7000: 2020-02-25 17:02:08.277470\n",
      "8000: 2020-02-25 17:11:14.227242\n",
      "9000: 2020-02-25 17:20:17.122729\n",
      "10000: 2020-02-25 17:29:22.014507\n",
      "11000: 2020-02-25 17:38:22.485881\n",
      "12000: 2020-02-25 17:47:21.191107\n",
      "13000: 2020-02-25 17:56:20.837243\n",
      "14000: 2020-02-25 18:05:16.776579\n",
      "15000: 2020-02-25 18:14:12.671045\n",
      "16000: 2020-02-25 18:23:10.843381\n",
      "17000: 2020-02-25 18:32:07.180465\n",
      "18000: 2020-02-25 18:41:04.395176\n",
      "19000: 2020-02-25 18:50:02.363179\n",
      "20000: 2020-02-25 18:59:03.644262\n",
      "21000: 2020-02-25 19:08:01.396308\n",
      "22000: 2020-02-25 19:16:58.890631\n",
      "23000: 2020-02-25 19:25:57.199601\n",
      "24000: 2020-02-25 19:34:53.160128\n",
      "25000: 2020-02-25 19:43:50.036412\n",
      "26000: 2020-02-25 19:52:46.386559\n",
      "27000: 2020-02-25 20:01:41.670630\n",
      "28000: 2020-02-25 20:10:35.965356\n",
      "29000: 2020-02-25 20:19:35.547980\n",
      "30000: 2020-02-25 20:28:32.558323\n",
      "31000: 2020-02-25 20:37:27.954154\n",
      "32000: 2020-02-25 20:46:23.734609\n",
      "33000: 2020-02-25 20:55:17.778957\n",
      "34000: 2020-02-25 21:04:12.254971\n",
      "35000: 2020-02-25 21:13:07.763017\n",
      "36000: 2020-02-25 21:22:02.828377\n",
      "37000: 2020-02-25 21:30:57.535872\n",
      "38000: 2020-02-25 21:39:53.393331\n",
      "39000: 2020-02-25 21:48:51.005093\n",
      "40000: 2020-02-25 21:57:47.793100\n",
      "41000: 2020-02-25 22:06:44.331268\n",
      "42000: 2020-02-25 22:15:41.456626\n",
      "43000: 2020-02-25 22:24:36.677152\n",
      "44000: 2020-02-25 22:33:31.928377\n",
      "45000: 2020-02-25 22:42:27.238418\n",
      "46000: 2020-02-25 22:51:23.046800\n",
      "47000: 2020-02-25 23:00:25.715208\n",
      "48000: 2020-02-25 23:09:05.556720\n",
      "49000: 2020-02-25 23:17:43.591503\n",
      "50000: 2020-02-25 23:26:19.821634\n",
      "51000: 2020-02-25 23:34:54.007729\n",
      "52000: 2020-02-25 23:43:30.713618\n",
      "53000: 2020-02-25 23:52:06.108631\n",
      "54000: 2020-02-26 00:00:45.059075\n"
     ]
    }
   ],
   "source": [
    "# Calculate top-n recommendations to all users\n",
    "if recalculate_topn:\n",
    "    n = 30\n",
    "    top_n = {}\n",
    "    all_users = algo.trainset._raw2inner_id_users.keys()\n",
    "    all_items = algo.trainset._raw2inner_id_items.keys()\n",
    "    \n",
    "    top_n_start_time = datetime.datetime.now()\n",
    "    for index, u in enumerate(all_users):\n",
    "        user_recommendations = []\n",
    "        for i in all_items:\n",
    "            prediction = algo.predict(u, i)\n",
    "            user_recommendations.append((prediction.iid, prediction.est))\n",
    "        user_recommendations.sort(key=lambda x: x[1], reverse=True)\n",
    "        top_n[u] = user_recommendations[:n]\n",
    "        if index == 100 or index % 1000 == 0: # Debug\n",
    "            print(str(index) + \": \" + str(datetime.datetime.now()))\n",
    "    top_n_end_time = datetime.datetime.now()\n",
    "    print(\"Top-n calculation duration: \" + str(top_n_end_time - top_n_start_time))\n",
    "    \n",
    "    if development_set:\n",
    "        with open(\"top_n-100k.pickle\", \"wb+\") as fp:\n",
    "            pickle.dump(top_n, fp)\n",
    "    else:\n",
    "        with open(\"top_n30-25m.pickle\", \"wb+\") as fp:\n",
    "            pickle.dump(top_n, fp)\n",
    "else:\n",
    "    if development_set:\n",
    "        with open(\"top_n-100k.pickle\", \"rb\") as fp:\n",
    "            top_n = pickle.load(fp)\n",
    "    else:\n",
    "        with open(\"top_n20-20m.pickle\", \"rb\") as fp:\n",
    "            top_n = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_n_items = [ [x[0] for x in row] for row in top_n.values()]\n",
    "top_n_items[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if recalculate_association_rules:\n",
    "    # Calculate association rules from top-n\n",
    "    te = TransactionEncoder()\n",
    "    te_ary = te.fit(top_n_items).transform(top_n_items, sparse=True)\n",
    "    topn_df = pd.DataFrame.sparse.from_spmatrix(te_ary, columns=te.columns_)\n",
    "    print(\"Sparse df created\")\n",
    "\n",
    "    apriori_start_time = datetime.datetime.now()\n",
    "    frequent_itemsets = apriori(topn_df, min_support=0.005, verbose=1, low_memory=True, use_colnames=True, max_len=4)\n",
    "    apriori_end_time = datetime.datetime.now()\n",
    "    print(\"Training duration: \" + str(apriori_end_time - apriori_start_time))\n",
    "\n",
    "    frequent_itemsets['length'] = frequent_itemsets['itemsets'].apply(lambda x: len(x))\n",
    "    print(frequent_itemsets)\n",
    "\n",
    "    frequent_itemsets[(frequent_itemsets['length'] == 2)]\n",
    "    rules = association_rules(frequent_itemsets)\n",
    "    if development_set:\n",
    "        with open(\"association-rules-100k.pickle\", \"wb+\") as fp:\n",
    "            pickle.dump(rules, fp)\n",
    "    else:\n",
    "        with open(\"association-rules-25m-n30.pickle\", \"wb+\") as fp:\n",
    "            pickle.dump(rules, fp)\n",
    "else:\n",
    "    if development_set:\n",
    "        with open(\"association-rules-100k.pickle\", \"rb\") as fp:\n",
    "            rules = pickle.load(fp)\n",
    "    else:\n",
    "        with open(\"association-rules-20m.pickle\", \"rb\") as fp:\n",
    "            rules = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      antecedents consequents  antecedent support  \\\n",
      "5                            (17)       (527)            0.078379   \n",
      "15                           (50)       (318)            0.393811   \n",
      "16                         (2858)        (50)            0.202776   \n",
      "17                         (4226)        (50)            0.165590   \n",
      "18                         (6016)        (50)            0.132815   \n",
      "...                           ...         ...                 ...   \n",
      "1177150    (93040, 93988, 108583)    (100553)            0.062306   \n",
      "1177239   (100553, 101850, 93988)    (108583)            0.065982   \n",
      "1177240   (101850, 93988, 108583)    (100553)            0.063758   \n",
      "1177337  (100553, 105250, 101850)    (108583)            0.087680   \n",
      "1177338  (101850, 105250, 108583)    (100553)            0.085701   \n",
      "\n",
      "         consequent support   support  confidence      lift  leverage  \\\n",
      "5                  0.421278  0.064718    0.825702  1.959996  0.031699   \n",
      "15                 0.799347  0.356458    0.905152  1.132364  0.041667   \n",
      "16                 0.393811  0.171828    0.847381  2.151748  0.091973   \n",
      "17                 0.393811  0.160528    0.969433  2.461673  0.095317   \n",
      "18                 0.393811  0.128967    0.971023  2.465712  0.076663   \n",
      "...                     ...       ...         ...       ...       ...   \n",
      "1177150            0.508156  0.055822    0.895932  1.763106  0.024161   \n",
      "1177239            0.528431  0.062624    0.949114  1.796097  0.027757   \n",
      "1177240            0.508156  0.062624    0.982220  1.932911  0.030225   \n",
      "1177337            0.528431  0.082293    0.938565  1.776136  0.035960   \n",
      "1177338            0.508156  0.082293    0.960233  1.889643  0.038743   \n",
      "\n",
      "         conviction  consequents_length  antecedents_length  \n",
      "5          3.320313                   1                   1  \n",
      "15         2.115523                   1                   1  \n",
      "16         3.971913                   1                   1  \n",
      "17        19.831303                   1                   1  \n",
      "18        20.919792                   1                   1  \n",
      "...             ...                 ...                 ...  \n",
      "1177150    4.726197                   1                   3  \n",
      "1177239    9.267091                   1                   3  \n",
      "1177240   27.662329                   1                   3  \n",
      "1177337    7.675954                   1                   3  \n",
      "1177338   12.368010                   1                   3  \n",
      "\n",
      "[49116 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "rules['consequents_length'] = rules['consequents'].apply(lambda x: len(x))\n",
    "rules['antecedents_length'] = rules['antecedents'].apply(lambda x: len(x))\n",
    "filtered_rules = rules[(rules['support'] > 0.05) &\n",
    "      (rules['confidence'] > 0.3) & (rules['antecedents_length'] < 4) & (rules['consequents_length'] == 1)]\n",
    "print(filtered_rules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>antecedents</th>\n",
       "      <th>consequents</th>\n",
       "      <th>antecedent support</th>\n",
       "      <th>consequent support</th>\n",
       "      <th>support</th>\n",
       "      <th>confidence</th>\n",
       "      <th>lift</th>\n",
       "      <th>leverage</th>\n",
       "      <th>conviction</th>\n",
       "      <th>consequents_length</th>\n",
       "      <th>antecedents_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>(47)</td>\n",
       "      <td>(2959)</td>\n",
       "      <td>0.029929</td>\n",
       "      <td>0.335851</td>\n",
       "      <td>0.029157</td>\n",
       "      <td>0.974186</td>\n",
       "      <td>2.900649</td>\n",
       "      <td>0.019105</td>\n",
       "      <td>25.728019</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>81</td>\n",
       "      <td>(223)</td>\n",
       "      <td>(2959)</td>\n",
       "      <td>0.026861</td>\n",
       "      <td>0.335851</td>\n",
       "      <td>0.024030</td>\n",
       "      <td>0.894624</td>\n",
       "      <td>2.663752</td>\n",
       "      <td>0.015009</td>\n",
       "      <td>6.302639</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>101</td>\n",
       "      <td>(288)</td>\n",
       "      <td>(2959)</td>\n",
       "      <td>0.012066</td>\n",
       "      <td>0.335851</td>\n",
       "      <td>0.010246</td>\n",
       "      <td>0.849192</td>\n",
       "      <td>2.528479</td>\n",
       "      <td>0.006194</td>\n",
       "      <td>4.403941</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>417</td>\n",
       "      <td>(665)</td>\n",
       "      <td>(2959)</td>\n",
       "      <td>0.018015</td>\n",
       "      <td>0.335851</td>\n",
       "      <td>0.016275</td>\n",
       "      <td>0.903407</td>\n",
       "      <td>2.689904</td>\n",
       "      <td>0.010225</td>\n",
       "      <td>6.875734</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>465</td>\n",
       "      <td>(778)</td>\n",
       "      <td>(2959)</td>\n",
       "      <td>0.088481</td>\n",
       "      <td>0.335851</td>\n",
       "      <td>0.074278</td>\n",
       "      <td>0.839481</td>\n",
       "      <td>2.499564</td>\n",
       "      <td>0.044562</td>\n",
       "      <td>4.137510</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>992860</td>\n",
       "      <td>(100553, 94466, 108583)</td>\n",
       "      <td>(2959)</td>\n",
       "      <td>0.121544</td>\n",
       "      <td>0.335851</td>\n",
       "      <td>0.106171</td>\n",
       "      <td>0.873522</td>\n",
       "      <td>2.600923</td>\n",
       "      <td>0.065351</td>\n",
       "      <td>5.251114</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>992864</td>\n",
       "      <td>(94466, 105250, 104069)</td>\n",
       "      <td>(2959)</td>\n",
       "      <td>0.009185</td>\n",
       "      <td>0.335851</td>\n",
       "      <td>0.008621</td>\n",
       "      <td>0.938679</td>\n",
       "      <td>2.794928</td>\n",
       "      <td>0.005537</td>\n",
       "      <td>10.830739</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>992866</td>\n",
       "      <td>(94466, 104069, 108583)</td>\n",
       "      <td>(2959)</td>\n",
       "      <td>0.012391</td>\n",
       "      <td>0.335851</td>\n",
       "      <td>0.011849</td>\n",
       "      <td>0.956294</td>\n",
       "      <td>2.847376</td>\n",
       "      <td>0.007688</td>\n",
       "      <td>15.195731</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>992868</td>\n",
       "      <td>(94466, 105250, 108583)</td>\n",
       "      <td>(2959)</td>\n",
       "      <td>0.053916</td>\n",
       "      <td>0.335851</td>\n",
       "      <td>0.043165</td>\n",
       "      <td>0.800589</td>\n",
       "      <td>2.383764</td>\n",
       "      <td>0.025057</td>\n",
       "      <td>3.330558</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>992878</td>\n",
       "      <td>(100553, 99114, 108583)</td>\n",
       "      <td>(2959)</td>\n",
       "      <td>0.013026</td>\n",
       "      <td>0.335851</td>\n",
       "      <td>0.013026</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.977512</td>\n",
       "      <td>0.008651</td>\n",
       "      <td>inf</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20487 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    antecedents consequents  antecedent support  \\\n",
       "14                         (47)      (2959)            0.029929   \n",
       "81                        (223)      (2959)            0.026861   \n",
       "101                       (288)      (2959)            0.012066   \n",
       "417                       (665)      (2959)            0.018015   \n",
       "465                       (778)      (2959)            0.088481   \n",
       "...                         ...         ...                 ...   \n",
       "992860  (100553, 94466, 108583)      (2959)            0.121544   \n",
       "992864  (94466, 105250, 104069)      (2959)            0.009185   \n",
       "992866  (94466, 104069, 108583)      (2959)            0.012391   \n",
       "992868  (94466, 105250, 108583)      (2959)            0.053916   \n",
       "992878  (100553, 99114, 108583)      (2959)            0.013026   \n",
       "\n",
       "        consequent support   support  confidence      lift  leverage  \\\n",
       "14                0.335851  0.029157    0.974186  2.900649  0.019105   \n",
       "81                0.335851  0.024030    0.894624  2.663752  0.015009   \n",
       "101               0.335851  0.010246    0.849192  2.528479  0.006194   \n",
       "417               0.335851  0.016275    0.903407  2.689904  0.010225   \n",
       "465               0.335851  0.074278    0.839481  2.499564  0.044562   \n",
       "...                    ...       ...         ...       ...       ...   \n",
       "992860            0.335851  0.106171    0.873522  2.600923  0.065351   \n",
       "992864            0.335851  0.008621    0.938679  2.794928  0.005537   \n",
       "992866            0.335851  0.011849    0.956294  2.847376  0.007688   \n",
       "992868            0.335851  0.043165    0.800589  2.383764  0.025057   \n",
       "992878            0.335851  0.013026    1.000000  2.977512  0.008651   \n",
       "\n",
       "        conviction  consequents_length  antecedents_length  \n",
       "14       25.728019                   1                   1  \n",
       "81        6.302639                   1                   1  \n",
       "101       4.403941                   1                   1  \n",
       "417       6.875734                   1                   1  \n",
       "465       4.137510                   1                   1  \n",
       "...            ...                 ...                 ...  \n",
       "992860    5.251114                   1                   3  \n",
       "992864   10.830739                   1                   3  \n",
       "992866   15.195731                   1                   3  \n",
       "992868    3.330558                   1                   3  \n",
       "992878         inf                   1                   3  \n",
       "\n",
       "[20487 rows x 11 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movieId = 2959\n",
    "filtered_rules.loc[filtered_rules['consequents'].apply(lambda cons: True if movieId in cons else False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "2003\n",
      "4003\n",
      "6003\n",
      "8003\n",
      "10003\n",
      "12003\n",
      "14003\n",
      "16003\n",
      "18003\n",
      "20003\n",
      "22003\n",
      "24003\n",
      "26003\n",
      "28003\n",
      "30003\n",
      "32003\n",
      "34003\n",
      "36003\n",
      "38003\n",
      "40003\n",
      "42003\n",
      "44003\n",
      "46003\n",
      "48003\n",
      "50003\n",
      "52003\n",
      "54003\n",
      "56003\n",
      "58003\n",
      "60003\n",
      "62003\n",
      "64003\n",
      "66003\n",
      "68003\n",
      "70003\n",
      "72003\n",
      "74003\n",
      "76003\n",
      "78003\n",
      "80003\n",
      "82003\n",
      "84003\n",
      "86003\n",
      "88003\n",
      "90003\n",
      "92003\n",
      "94003\n",
      "96003\n",
      "98003\n",
      "100003\n",
      "102003\n",
      "104003\n",
      "106003\n",
      "108003\n",
      "110003\n",
      "112003\n",
      "114003\n",
      "116003\n",
      "118003\n",
      "120003\n",
      "122003\n",
      "124003\n",
      "126003\n",
      "128003\n",
      "130003\n",
      "132003\n",
      "134003\n",
      "136003\n",
      "138003\n",
      "Model fidelity calculation duration: 9:19:48.485246\n",
      "0.2180952380952381\n"
     ]
    }
   ],
   "source": [
    "# Calculate model fidelity\n",
    "mf_start_time = datetime.datetime.now()\n",
    "recommendations_amount = 0\n",
    "explainable_amount = 0\n",
    "for k, (u, recommendations) in enumerate(top_n.items()):\n",
    "    if k % 2000 == 3: # Only take a small sample\n",
    "        print(str(k))\n",
    "        for (i, rating) in recommendations:\n",
    "            recommendations_amount += 1\n",
    "            rows = filtered_rules.loc[filtered_rules['consequents']\n",
    "                .apply(lambda cons: True if i in cons else False)]\n",
    "            for index, row in rows.iterrows():\n",
    "                antecedents = list(row['antecedents'])\n",
    "                user_ratings = [ algo.trainset.to_raw_iid(x[0]) for x in algo.trainset.ur[algo.trainset.to_inner_uid(u)] ]\n",
    "                if all([x in user_ratings for x in antecedents]):\n",
    "                    explainable_amount += 1\n",
    "                    break;\n",
    "                \n",
    "mf_end_time = datetime.datetime.now()\n",
    "print(\"Model fidelity calculation duration: \" + str(top_n_end_time - top_n_start_time))\n",
    "\n",
    "model_fidelity = explainable_amount / recommendations_amount\n",
    "print(model_fidelity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
