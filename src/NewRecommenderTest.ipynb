{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext Cython\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import pickle\n",
    "from surprise import SVD\n",
    "from surprise import Dataset\n",
    "from surprise import Reader\n",
    "from surprise import accuracy\n",
    "from surprise.model_selection import train_test_split\n",
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "from mlxtend.frequent_patterns import apriori\n",
    "from mlxtend.frequent_patterns import association_rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from recommender_algo.editable_svd import EditableSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "development_set = False\n",
    "retrain_model = False\n",
    "recalculate_topn = False\n",
    "recalculate_association_rules = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if retrain_model:\n",
    "    if development_set:\n",
    "        filename = \"../data/ml_100k/ratings.csv\"\n",
    "    else:\n",
    "        filename = \"../data/ml-20m/ratings.csv\"\n",
    "    ratings_df = pd.read_csv(filename, dtype={\n",
    "        'userId': np.int32,\n",
    "        'movieId': np.int32,\n",
    "        'rating': np.float32,\n",
    "        'timestamp': np.int32,\n",
    "    })\n",
    "\n",
    "    reader = Reader(rating_scale=(1, 5))\n",
    "    data = Dataset.load_from_df(ratings_df[['userId', 'movieId', 'rating']], reader)\n",
    "\n",
    "    trainset, testset = train_test_split(data, test_size=.25, random_state=42)\n",
    "    algo = EditableSVD(n_factors=10)\n",
    "\n",
    "    train_start_time = datetime.datetime.now()\n",
    "    algo.fit(trainset)\n",
    "    train_end_time = datetime.datetime.now()\n",
    "    print(\"Training duration: \" + str(train_end_time - train_start_time))\n",
    "    \n",
    "    predictions = algo.test(testset)\n",
    "    accuracy.rmse(predictions)\n",
    "    print(accuracy)\n",
    "    \n",
    "    if development_set:\n",
    "        with open(\"algo-100k.pickle\", \"wb+\") as fp:\n",
    "            pickle.dump(algo, fp)\n",
    "    else:\n",
    "        with open(\"algo-20m.pickle\", \"wb+\") as fp:\n",
    "            pickle.dump(algo, fp)\n",
    "else:\n",
    "    if development_set:\n",
    "        with open(\"algo-100k.pickle\", \"rb\") as fp:\n",
    "            algo = pickle.load(fp)\n",
    "    else:\n",
    "        with open(\"algo-20m.pickle\", \"rb\") as fp:\n",
    "            algo = pickle.load(fp)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate top-n recommendations to all users\n",
    "if recalculate_topn:\n",
    "    n = 20\n",
    "    top_n = {}\n",
    "    all_users = algo.trainset._raw2inner_id_users.keys()\n",
    "    all_items = algo.trainset._raw2inner_id_items.keys()\n",
    "    \n",
    "    top_n_start_time = datetime.datetime.now()\n",
    "    for index, u in enumerate(all_users):\n",
    "        user_recommendations = []\n",
    "        for i in all_items:\n",
    "            prediction = algo.predict(u, i)\n",
    "            user_recommendations.append((prediction.iid, prediction.est))\n",
    "        user_recommendations.sort(key=lambda x: x[1], reverse=True)\n",
    "        top_n[u] = user_recommendations[:n]\n",
    "        if index == 100 or index % 10000 == 0: # Debug\n",
    "            print(str(index))\n",
    "    top_n_end_time = datetime.datetime.now()\n",
    "    print(\"Top-n calculation duration: \" + str(top_n_end_time - top_n_start_time))\n",
    "    \n",
    "    if development_set:\n",
    "        with open(\"top_n-100k.pickle\", \"wb+\") as fp:\n",
    "            pickle.dump(top_n, fp)\n",
    "    else:\n",
    "        with open(\"top_n20-20m.pickle\", \"wb+\") as fp:\n",
    "            pickle.dump(top_n, fp)\n",
    "else:\n",
    "    if development_set:\n",
    "        with open(\"top_n-100k.pickle\", \"rb\") as fp:\n",
    "            top_n = pickle.load(fp)\n",
    "    else:\n",
    "        with open(\"top_n20-20m.pickle\", \"rb\") as fp:\n",
    "            top_n = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[356,\n",
       " 2329,\n",
       " 3949,\n",
       " 318,\n",
       " 527,\n",
       " 2571,\n",
       " 2959,\n",
       " 3578,\n",
       " 2324,\n",
       " 48394,\n",
       " 3147,\n",
       " 48780,\n",
       " 26674,\n",
       " 110,\n",
       " 47,\n",
       " 1704,\n",
       " 4226,\n",
       " 1584,\n",
       " 7254,\n",
       " 4995]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_n_items = [ [x[0] for x in row] for row in top_n.values()]\n",
    "top_n_items[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if recalculate_association_rules:\n",
    "    # Calculate association rules from top-n\n",
    "    te = TransactionEncoder()\n",
    "    te_ary = te.fit(top_n_items).transform(top_n_items, sparse=True)\n",
    "    topn_df = pd.DataFrame.sparse.from_spmatrix(te_ary, columns=te.columns_)\n",
    "    print(\"Sparse df created\")\n",
    "\n",
    "    apriori_start_time = datetime.datetime.now()\n",
    "    frequent_itemsets = apriori(topn_df, min_support=0.005, verbose=1, low_memory=True, use_colnames=True)\n",
    "    apriori_end_time = datetime.datetime.now()\n",
    "    print(\"Training duration: \" + str(apriori_end_time - apriori_start_time))\n",
    "\n",
    "    frequent_itemsets['length'] = frequent_itemsets['itemsets'].apply(lambda x: len(x))\n",
    "    print(frequent_itemsets)\n",
    "\n",
    "    frequent_itemsets[(frequent_itemsets['length'] == 2)]\n",
    "    rules = association_rules(frequent_itemsets)\n",
    "    if development_set:\n",
    "        with open(\"association-rules-100k.pickle\", \"wb+\") as fp:\n",
    "            pickle.dump(rules, fp)\n",
    "    else:\n",
    "        with open(\"association-rules-20m.pickle\", \"wb+\") as fp:\n",
    "            pickle.dump(rules, fp)\n",
    "else:\n",
    "    if development_set:\n",
    "        with open(\"association-rules-100k.pickle\", \"rb\") as fp:\n",
    "            rules = pickle.load(fp)\n",
    "    else:\n",
    "        with open(\"association-rules-20m.pickle\", \"rb\") as fp:\n",
    "            rules = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   antecedents consequents  antecedent support  \\\n",
      "0                         (25)       (296)            0.012058   \n",
      "1                         (36)       (527)            0.007791   \n",
      "2                         (47)      (2959)            0.037626   \n",
      "3                       (4226)        (50)            0.059952   \n",
      "4                       (5782)        (50)            0.007264   \n",
      "...                        ...         ...                 ...   \n",
      "22985  (81736, 108583, 117192)     (26109)            0.006795   \n",
      "22986    (81834, 69844, 40815)     (88125)            0.006758   \n",
      "22987    (69844, 88125, 40815)     (81834)            0.007387   \n",
      "22989    (86345, 86347, 92535)     (86377)            0.009871   \n",
      "22990    (86377, 86347, 92535)     (86345)            0.010549   \n",
      "\n",
      "       consequent support   support  confidence       lift  leverage  \\\n",
      "0                0.251832  0.010022    0.831138   3.300363  0.006985   \n",
      "1                0.311987  0.006636    0.851715   2.729969  0.004205   \n",
      "2                0.138029  0.031142    0.827672   5.996381  0.025949   \n",
      "3                0.380120  0.054797    0.914007   2.404520  0.032008   \n",
      "4                0.380120  0.005971    0.822068   2.162651  0.003210   \n",
      "...                   ...       ...         ...        ...       ...   \n",
      "22985            0.265696  0.005473    0.805526   3.031761  0.003668   \n",
      "22986            0.068574  0.006564    0.971154  14.162157  0.006100   \n",
      "22987            0.027951  0.006564    0.888563  31.790174  0.006357   \n",
      "22989            0.056840  0.008730    0.884418  15.559675  0.008169   \n",
      "22990            0.043316  0.008730    0.827515  19.104032  0.008273   \n",
      "\n",
      "       conviction  consequents_length  antecedents_length  \n",
      "0        4.430639                   1                   1  \n",
      "1        4.639788                   1                   1  \n",
      "2        5.001930                   1                   1  \n",
      "3        7.208489                   1                   1  \n",
      "4        3.483793                   1                   1  \n",
      "...           ...                 ...                 ...  \n",
      "22985    3.775849                   1                   3  \n",
      "22986   32.289439                   1                   3  \n",
      "22987    8.722862                   1                   3  \n",
      "22989    8.160121                   1                   3  \n",
      "22990    5.546488                   1                   3  \n",
      "\n",
      "[22077 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "rules['consequents_length'] = rules['consequents'].apply(lambda x: len(x))\n",
    "rules['antecedents_length'] = rules['antecedents'].apply(lambda x: len(x))\n",
    "filtered_rules = rules[(rules['support'] > 0.005) &\n",
    "      (rules['confidence'] > 0.3) & (rules['antecedents_length'] < 4) & (rules['consequents_length'] == 1)]\n",
    "print(filtered_rules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>antecedents</th>\n",
       "      <th>consequents</th>\n",
       "      <th>antecedent support</th>\n",
       "      <th>consequent support</th>\n",
       "      <th>support</th>\n",
       "      <th>confidence</th>\n",
       "      <th>lift</th>\n",
       "      <th>leverage</th>\n",
       "      <th>conviction</th>\n",
       "      <th>consequents_length</th>\n",
       "      <th>antecedents_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>(47)</td>\n",
       "      <td>(2959)</td>\n",
       "      <td>0.037626</td>\n",
       "      <td>0.138029</td>\n",
       "      <td>0.031142</td>\n",
       "      <td>0.827672</td>\n",
       "      <td>5.996381</td>\n",
       "      <td>0.025949</td>\n",
       "      <td>5.001930</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>81</td>\n",
       "      <td>(2542)</td>\n",
       "      <td>(2959)</td>\n",
       "      <td>0.013257</td>\n",
       "      <td>0.138029</td>\n",
       "      <td>0.011416</td>\n",
       "      <td>0.861111</td>\n",
       "      <td>6.238641</td>\n",
       "      <td>0.009586</td>\n",
       "      <td>6.206194</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>83</td>\n",
       "      <td>(4878)</td>\n",
       "      <td>(2959)</td>\n",
       "      <td>0.005885</td>\n",
       "      <td>0.138029</td>\n",
       "      <td>0.005112</td>\n",
       "      <td>0.868712</td>\n",
       "      <td>6.293706</td>\n",
       "      <td>0.004300</td>\n",
       "      <td>6.565483</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>155</td>\n",
       "      <td>(50, 47)</td>\n",
       "      <td>(2959)</td>\n",
       "      <td>0.027229</td>\n",
       "      <td>0.138029</td>\n",
       "      <td>0.022730</td>\n",
       "      <td>0.834792</td>\n",
       "      <td>6.047961</td>\n",
       "      <td>0.018972</td>\n",
       "      <td>5.217486</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>161</td>\n",
       "      <td>(296, 47)</td>\n",
       "      <td>(2959)</td>\n",
       "      <td>0.024666</td>\n",
       "      <td>0.138029</td>\n",
       "      <td>0.022803</td>\n",
       "      <td>0.924473</td>\n",
       "      <td>6.697690</td>\n",
       "      <td>0.019398</td>\n",
       "      <td>11.412768</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21944</td>\n",
       "      <td>(3275, 4011, 2542)</td>\n",
       "      <td>(2959)</td>\n",
       "      <td>0.005899</td>\n",
       "      <td>0.138029</td>\n",
       "      <td>0.005026</td>\n",
       "      <td>0.851897</td>\n",
       "      <td>6.171887</td>\n",
       "      <td>0.004211</td>\n",
       "      <td>5.820088</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21956</td>\n",
       "      <td>(4226, 2571, 94466)</td>\n",
       "      <td>(2959)</td>\n",
       "      <td>0.006080</td>\n",
       "      <td>0.138029</td>\n",
       "      <td>0.005026</td>\n",
       "      <td>0.826603</td>\n",
       "      <td>5.988636</td>\n",
       "      <td>0.004186</td>\n",
       "      <td>4.971095</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22162</td>\n",
       "      <td>(4226, 2858, 3949)</td>\n",
       "      <td>(2959)</td>\n",
       "      <td>0.010297</td>\n",
       "      <td>0.138029</td>\n",
       "      <td>0.008773</td>\n",
       "      <td>0.852034</td>\n",
       "      <td>6.172876</td>\n",
       "      <td>0.007352</td>\n",
       "      <td>5.825456</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22173</td>\n",
       "      <td>(7361, 4226, 3949)</td>\n",
       "      <td>(2959)</td>\n",
       "      <td>0.009329</td>\n",
       "      <td>0.138029</td>\n",
       "      <td>0.007834</td>\n",
       "      <td>0.839783</td>\n",
       "      <td>6.084124</td>\n",
       "      <td>0.006547</td>\n",
       "      <td>5.380034</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22174</td>\n",
       "      <td>(4226, 94466, 3949)</td>\n",
       "      <td>(2959)</td>\n",
       "      <td>0.007683</td>\n",
       "      <td>0.138029</td>\n",
       "      <td>0.006600</td>\n",
       "      <td>0.859023</td>\n",
       "      <td>6.223510</td>\n",
       "      <td>0.005539</td>\n",
       "      <td>6.114250</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>260 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               antecedents consequents  antecedent support  \\\n",
       "2                     (47)      (2959)            0.037626   \n",
       "81                  (2542)      (2959)            0.013257   \n",
       "83                  (4878)      (2959)            0.005885   \n",
       "155               (50, 47)      (2959)            0.027229   \n",
       "161              (296, 47)      (2959)            0.024666   \n",
       "...                    ...         ...                 ...   \n",
       "21944   (3275, 4011, 2542)      (2959)            0.005899   \n",
       "21956  (4226, 2571, 94466)      (2959)            0.006080   \n",
       "22162   (4226, 2858, 3949)      (2959)            0.010297   \n",
       "22173   (7361, 4226, 3949)      (2959)            0.009329   \n",
       "22174  (4226, 94466, 3949)      (2959)            0.007683   \n",
       "\n",
       "       consequent support   support  confidence      lift  leverage  \\\n",
       "2                0.138029  0.031142    0.827672  5.996381  0.025949   \n",
       "81               0.138029  0.011416    0.861111  6.238641  0.009586   \n",
       "83               0.138029  0.005112    0.868712  6.293706  0.004300   \n",
       "155              0.138029  0.022730    0.834792  6.047961  0.018972   \n",
       "161              0.138029  0.022803    0.924473  6.697690  0.019398   \n",
       "...                   ...       ...         ...       ...       ...   \n",
       "21944            0.138029  0.005026    0.851897  6.171887  0.004211   \n",
       "21956            0.138029  0.005026    0.826603  5.988636  0.004186   \n",
       "22162            0.138029  0.008773    0.852034  6.172876  0.007352   \n",
       "22173            0.138029  0.007834    0.839783  6.084124  0.006547   \n",
       "22174            0.138029  0.006600    0.859023  6.223510  0.005539   \n",
       "\n",
       "       conviction  consequents_length  antecedents_length  \n",
       "2        5.001930                   1                   1  \n",
       "81       6.206194                   1                   1  \n",
       "83       6.565483                   1                   1  \n",
       "155      5.217486                   1                   2  \n",
       "161     11.412768                   1                   2  \n",
       "...           ...                 ...                 ...  \n",
       "21944    5.820088                   1                   3  \n",
       "21956    4.971095                   1                   3  \n",
       "22162    5.825456                   1                   3  \n",
       "22173    5.380034                   1                   3  \n",
       "22174    6.114250                   1                   3  \n",
       "\n",
       "[260 rows x 11 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movieId = 2959\n",
    "filtered_rules.loc[filtered_rules['consequents'].apply(lambda cons: True if movieId in cons else False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model fidelity calculation duration: 9:57:00.473035\n",
      "0.15422382671480145\n"
     ]
    }
   ],
   "source": [
    "# Calculate model fidelity\n",
    "mf_start_time = datetime.datetime.now()\n",
    "recommendations_amount = 0\n",
    "explainable_amount = 0\n",
    "for k, (u, recommendations) in enumerate(top_n.items()):\n",
    "    if k % 100 == 0: # Only take a small sample\n",
    "        for (i, rating) in recommendations:\n",
    "            recommendations_amount += 1\n",
    "            rows = filtered_rules.loc[filtered_rules['consequents']\n",
    "                .apply(lambda cons: True if i in cons else False)]\n",
    "            for index, row in rows.iterrows():\n",
    "                antecedents = list(row['antecedents'])\n",
    "                user_ratings = [ algo.trainset.to_raw_iid(x[0]) for x in algo.trainset.ur[algo.trainset.to_inner_uid(u)] ]\n",
    "                if all([x in user_ratings for x in antecedents]):\n",
    "                    explainable_amount += 1\n",
    "                    break;\n",
    "                \n",
    "mf_end_time = datetime.datetime.now()\n",
    "print(\"Model fidelity calculation duration: \" + str(top_n_end_time - top_n_start_time))\n",
    "\n",
    "model_fidelity = explainable_amount / recommendations_amount\n",
    "print(model_fidelity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
