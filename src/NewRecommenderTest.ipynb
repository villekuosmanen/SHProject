{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext Cython\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import pickle\n",
    "from surprise import SVD\n",
    "from surprise import Dataset\n",
    "from surprise import Reader\n",
    "from surprise import accuracy\n",
    "from surprise.model_selection import train_test_split\n",
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "from mlxtend.frequent_patterns import apriori\n",
    "from mlxtend.frequent_patterns import association_rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from recommender_algo.editable_svd import EditableSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "development_set = False\n",
    "retrain_model = False\n",
    "recalculate_topn = False\n",
    "recalculate_association_rules = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if retrain_model:\n",
    "    if development_set:\n",
    "        filename = \"../data/ml_100k/ratings.csv\"\n",
    "    else:\n",
    "        filename = \"../data/ml-20m/ratings.csv\"\n",
    "    ratings_df = pd.read_csv(filename, dtype={\n",
    "        'userId': np.int32,\n",
    "        'movieId': np.int32,\n",
    "        'rating': np.float32,\n",
    "        'timestamp': np.int32,\n",
    "    })\n",
    "\n",
    "    reader = Reader(rating_scale=(1, 5))\n",
    "    data = Dataset.load_from_df(ratings_df[['userId', 'movieId', 'rating']], reader)\n",
    "\n",
    "    trainset, testset = train_test_split(data, test_size=.25)\n",
    "    algo = EditableSVD()\n",
    "\n",
    "    train_start_time = datetime.datetime.now()\n",
    "    algo.fit(trainset)\n",
    "    train_end_time = datetime.datetime.now()\n",
    "    print(\"Training duration: \" + str(train_end_time - train_start_time))\n",
    "    \n",
    "    predictions = algo.test(testset)\n",
    "    accuracy.rmse(predictions)\n",
    "    \n",
    "    if development_set:\n",
    "        with open(\"algo-100k.pickle\", \"wb+\") as fp:\n",
    "            pickle.dump(algo, fp)\n",
    "    else:\n",
    "        with open(\"algo-20m.pickle\", \"wb+\") as fp:\n",
    "            pickle.dump(algo, fp)\n",
    "else:\n",
    "    if development_set:\n",
    "        with open(\"algo-100k.pickle\", \"rb\") as fp:\n",
    "            algo = pickle.load(fp)\n",
    "    else:\n",
    "        with open(\"algo-20m.pickle\", \"rb\") as fp:\n",
    "            algo = pickle.load(fp)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate top-n recommendations to all users\n",
    "if recalculate_topn:\n",
    "    n = 10\n",
    "    top_n = []\n",
    "    all_users = algo.trainset._raw2inner_id_users.keys()\n",
    "    print(str(len(all_users)))\n",
    "    all_items = algo.trainset._raw2inner_id_items.keys()\n",
    "    \n",
    "    top_n_start_time = datetime.datetime.now()\n",
    "    for k, u in enumerate(all_users):\n",
    "        user_recommendations = []\n",
    "        for i in all_items:\n",
    "            prediction = algo.predict(u, i)\n",
    "            user_recommendations.append((prediction.iid, prediction.est))\n",
    "        user_recommendations.sort(key=lambda x: x[1], reverse=True)\n",
    "        top_n.append(user_recommendations[:n])\n",
    "        if k == 100: # Debug\n",
    "            print(str(k))\n",
    "    top_n_end_time = datetime.datetime.now()\n",
    "    print(\"Top-n calculation duration: \" + str(top_n_end_time - top_n_start_time))\n",
    "    \n",
    "    if development_set:\n",
    "        with open(\"top_n-100k.pickle\", \"wb+\") as fp:\n",
    "            pickle.dump(top_n, fp)\n",
    "    else:\n",
    "        with open(\"top_n-20m.pickle\", \"wb+\") as fp:\n",
    "            pickle.dump(top_n, fp)\n",
    "else:\n",
    "    if development_set:\n",
    "        with open(\"top_n-100k.pickle\", \"rb\") as fp:\n",
    "            top_n = pickle.load(fp)\n",
    "    else:\n",
    "        with open(\"top_n-20m.pickle\", \"rb\") as fp:\n",
    "            top_n = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[356, 2329, 3949, 318, 527, 2571, 2959, 3578, 2324, 48394]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_n_items = [ [x[0] for x in row] for row in top_n]\n",
    "top_n_items[1]\n",
    "\n",
    "# if development_set:\n",
    "#     with open(\"top_n-100k.pickle\", \"wb+\") as fp:\n",
    "#         pickle.dump(top_n, fp)\n",
    "# else:\n",
    "#     with open(\"top_n-20m.pickle\", \"wb+\") as fp:\n",
    "#         pickle.dump(top_n, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "if recalculate_association_rules:\n",
    "    # Calculate association rules from top-n\n",
    "    te = TransactionEncoder()\n",
    "    te_ary = te.fit(top_n_items).transform(top_n_items, sparse=True)\n",
    "    topn_df = pd.DataFrame.sparse.from_spmatrix(te_ary, columns=te.columns_)\n",
    "    print(\"Sparse df created\")\n",
    "\n",
    "    apriori_start_time = datetime.datetime.now()\n",
    "    frequent_itemsets = apriori(topn_df, min_support=0.01, verbose=1)\n",
    "    apriori_end_time = datetime.datetime.now()\n",
    "    print(\"Training duration: \" + str(apriori_end_time - apriori_start_time))\n",
    "\n",
    "    frequent_itemsets['length'] = frequent_itemsets['itemsets'].apply(lambda x: len(x))\n",
    "    print(frequent_itemsets)\n",
    "\n",
    "    # frequent_itemsets[(frequent_itemsets['length'] == 2)]\n",
    "    rules = association_rules(frequent_itemsets)\n",
    "    if development_set:\n",
    "        with open(\"association-rules-100k.pickle\", \"wb+\") as fp:\n",
    "            pickle.dump(rules, fp)\n",
    "    else:\n",
    "        with open(\"association-rules-20m.pickle\", \"wb+\") as fp:\n",
    "            pickle.dump(rules, fp)\n",
    "else:\n",
    "    if development_set:\n",
    "        with open(\"association-rules-100k.pickle\", \"rb\") as fp:\n",
    "            rules = pickle.load(fp)\n",
    "    else:\n",
    "        with open(\"association-rules-20m.pickle\", \"rb\") as fp:\n",
    "            rules = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         antecedents        consequents  antecedent support  \\\n",
      "0                             (4226)               (50)            0.015849   \n",
      "1                             (1196)              (260)            0.076437   \n",
      "2                             (1198)              (260)            0.036240   \n",
      "3                             (1210)              (260)            0.035338   \n",
      "5                              (778)              (296)            0.017445   \n",
      "...                              ...                ...                 ...   \n",
      "16453  (4993, 1221, 7502, 7153, 858)             (5952)            0.005394   \n",
      "16454       (5952, 4993, 1221, 7502)        (7153, 858)            0.006152   \n",
      "16455       (7153, 4993, 1221, 7502)        (5952, 858)            0.005914   \n",
      "16456        (4993, 858, 1221, 7502)       (5952, 7153)            0.005856   \n",
      "16457             (4993, 1221, 7502)  (5952, 7153, 858)            0.006397   \n",
      "\n",
      "       consequent support   support  confidence       lift  leverage  \\\n",
      "0                0.231687  0.012715    0.802278   3.462769  0.009043   \n",
      "1                0.126541  0.069224    0.905630   7.156829  0.059551   \n",
      "2                0.126541  0.030752    0.848575   6.705949  0.026167   \n",
      "3                0.126541  0.032262    0.912955   7.214712  0.027790   \n",
      "5                0.200429  0.016867    0.966887   4.824092  0.013371   \n",
      "...                   ...       ...         ...        ...       ...   \n",
      "16453            0.160586  0.005322    0.986613   6.143840  0.004455   \n",
      "16454            0.036514  0.005322    0.865023  23.689875  0.005097   \n",
      "16455            0.036233  0.005322    0.899878  24.835949  0.005107   \n",
      "16456            0.137213  0.005322    0.908755   6.622962  0.004518   \n",
      "16457            0.028817  0.005322    0.831828  28.865552  0.005137   \n",
      "\n",
      "       conviction  \n",
      "0        3.885824  \n",
      "1        9.255696  \n",
      "2        5.768279  \n",
      "3       10.034530  \n",
      "5       24.147047  \n",
      "...           ...  \n",
      "16453   62.704246  \n",
      "16454    7.138171  \n",
      "16455    9.625918  \n",
      "16456    9.455682  \n",
      "16457    5.774952  \n",
      "\n",
      "[1700 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "filtered_rules = rules[(rules['support'] > 0.005) &\n",
    "      (rules['confidence'] > 0.3)]\n",
    "print(filtered_rules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>antecedents</th>\n",
       "      <th>consequents</th>\n",
       "      <th>antecedent support</th>\n",
       "      <th>consequent support</th>\n",
       "      <th>support</th>\n",
       "      <th>confidence</th>\n",
       "      <th>lift</th>\n",
       "      <th>leverage</th>\n",
       "      <th>conviction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>(1208)</td>\n",
       "      <td>(1221)</td>\n",
       "      <td>0.008592</td>\n",
       "      <td>0.222827</td>\n",
       "      <td>0.007127</td>\n",
       "      <td>0.829412</td>\n",
       "      <td>3.722220</td>\n",
       "      <td>0.005212</td>\n",
       "      <td>4.555841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>(1213)</td>\n",
       "      <td>(1221)</td>\n",
       "      <td>0.018788</td>\n",
       "      <td>0.222827</td>\n",
       "      <td>0.017207</td>\n",
       "      <td>0.915834</td>\n",
       "      <td>4.110065</td>\n",
       "      <td>0.013020</td>\n",
       "      <td>9.233807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>(50, 1213)</td>\n",
       "      <td>(1221)</td>\n",
       "      <td>0.007856</td>\n",
       "      <td>0.222827</td>\n",
       "      <td>0.007141</td>\n",
       "      <td>0.909007</td>\n",
       "      <td>4.079428</td>\n",
       "      <td>0.005391</td>\n",
       "      <td>8.541051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>108</td>\n",
       "      <td>(296, 593)</td>\n",
       "      <td>(1221)</td>\n",
       "      <td>0.013300</td>\n",
       "      <td>0.222827</td>\n",
       "      <td>0.011199</td>\n",
       "      <td>0.842020</td>\n",
       "      <td>3.778801</td>\n",
       "      <td>0.008235</td>\n",
       "      <td>4.919424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>128</td>\n",
       "      <td>(296, 858)</td>\n",
       "      <td>(1221)</td>\n",
       "      <td>0.106756</td>\n",
       "      <td>0.222827</td>\n",
       "      <td>0.086763</td>\n",
       "      <td>0.812716</td>\n",
       "      <td>3.647292</td>\n",
       "      <td>0.062974</td>\n",
       "      <td>4.149693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1493</td>\n",
       "      <td>(593, 858, 1193, 318)</td>\n",
       "      <td>(1221)</td>\n",
       "      <td>0.008044</td>\n",
       "      <td>0.222827</td>\n",
       "      <td>0.006542</td>\n",
       "      <td>0.813285</td>\n",
       "      <td>3.649849</td>\n",
       "      <td>0.004749</td>\n",
       "      <td>4.162358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1496</td>\n",
       "      <td>(1193, 858, 7502, 318)</td>\n",
       "      <td>(1221)</td>\n",
       "      <td>0.009221</td>\n",
       "      <td>0.222827</td>\n",
       "      <td>0.007632</td>\n",
       "      <td>0.827721</td>\n",
       "      <td>3.714634</td>\n",
       "      <td>0.005578</td>\n",
       "      <td>4.511135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1516</td>\n",
       "      <td>(593, 858, 1193, 527)</td>\n",
       "      <td>(1221)</td>\n",
       "      <td>0.007842</td>\n",
       "      <td>0.222827</td>\n",
       "      <td>0.006484</td>\n",
       "      <td>0.826888</td>\n",
       "      <td>3.710893</td>\n",
       "      <td>0.004737</td>\n",
       "      <td>4.489413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1521</td>\n",
       "      <td>(1193, 858, 7502, 527)</td>\n",
       "      <td>(1221)</td>\n",
       "      <td>0.010484</td>\n",
       "      <td>0.222827</td>\n",
       "      <td>0.008643</td>\n",
       "      <td>0.824380</td>\n",
       "      <td>3.699640</td>\n",
       "      <td>0.006307</td>\n",
       "      <td>4.425314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1538</td>\n",
       "      <td>(912, 1193, 858, 923)</td>\n",
       "      <td>(1221)</td>\n",
       "      <td>0.008564</td>\n",
       "      <td>0.222827</td>\n",
       "      <td>0.006852</td>\n",
       "      <td>0.800169</td>\n",
       "      <td>3.590984</td>\n",
       "      <td>0.004944</td>\n",
       "      <td>3.889143</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>91 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 antecedents consequents  antecedent support  \\\n",
       "15                    (1208)      (1221)            0.008592   \n",
       "16                    (1213)      (1221)            0.018788   \n",
       "40                (50, 1213)      (1221)            0.007856   \n",
       "108               (296, 593)      (1221)            0.013300   \n",
       "128               (296, 858)      (1221)            0.106756   \n",
       "...                      ...         ...                 ...   \n",
       "1493   (593, 858, 1193, 318)      (1221)            0.008044   \n",
       "1496  (1193, 858, 7502, 318)      (1221)            0.009221   \n",
       "1516   (593, 858, 1193, 527)      (1221)            0.007842   \n",
       "1521  (1193, 858, 7502, 527)      (1221)            0.010484   \n",
       "1538   (912, 1193, 858, 923)      (1221)            0.008564   \n",
       "\n",
       "      consequent support   support  confidence      lift  leverage  conviction  \n",
       "15              0.222827  0.007127    0.829412  3.722220  0.005212    4.555841  \n",
       "16              0.222827  0.017207    0.915834  4.110065  0.013020    9.233807  \n",
       "40              0.222827  0.007141    0.909007  4.079428  0.005391    8.541051  \n",
       "108             0.222827  0.011199    0.842020  3.778801  0.008235    4.919424  \n",
       "128             0.222827  0.086763    0.812716  3.647292  0.062974    4.149693  \n",
       "...                  ...       ...         ...       ...       ...         ...  \n",
       "1493            0.222827  0.006542    0.813285  3.649849  0.004749    4.162358  \n",
       "1496            0.222827  0.007632    0.827721  3.714634  0.005578    4.511135  \n",
       "1516            0.222827  0.006484    0.826888  3.710893  0.004737    4.489413  \n",
       "1521            0.222827  0.008643    0.824380  3.699640  0.006307    4.425314  \n",
       "1538            0.222827  0.006852    0.800169  3.590984  0.004944    3.889143  \n",
       "\n",
       "[91 rows x 9 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movieId = 1221\n",
    "filtered_rules.loc[filtered_rules['consequents'].apply(lambda cons: True if movieId in cons else False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "138493\n",
      "[[(858, 4.215223830711985), (2324, 4.211003289190636), (1221, 4.183114383967304), (318, 4.173749882382581), (6016, 4.163693153751168), (3949, 4.1616164255726344), (1193, 4.150517708476085), (527, 4.13852418974071), (296, 4.130790446729069), (593, 4.12982833749897), (4973, 4.129341484669373), (7361, 4.1192479027512965), (48394, 4.099757297867061), (2858, 4.095806526153439), (50, 4.093276867518577), (2959, 4.089279398825941), (93040, 4.051945795162437), (55820, 4.04878321864231), (55247, 4.033375435495483), (1209, 4.03075054952057)], [(356, 4.6898414706009195), (2329, 4.603877430222737), (3949, 4.580710983439617), (318, 4.5690847208279175), (527, 4.541656473578388), (2571, 4.533214069267075), (2959, 4.524187092864716), (3578, 4.51631832551747), (2324, 4.503870916182875), (48394, 4.502967817785687), (3147, 4.485171484970195), (48780, 4.4810730473706855), (26674, 4.469488601839008), (110, 4.469473131266811), (47, 4.441107047477216), (1704, 4.431388687214991), (4226, 4.4201993237585), (1584, 4.419003089851493), (7254, 4.413035682526522), (4995, 4.410882773694404)], [(1035, 4.938607684203383), (919, 4.889035507152079), (912, 4.858002125767368), (920, 4.835556520873795), (1207, 4.8163171613972535), (953, 4.7867466732257435), (1947, 4.780200249124879), (969, 4.765909429269337), (527, 4.759661192792089), (7669, 4.709086731578688), (914, 4.704715136482341), (1, 4.663658609226436), (904, 4.6625138692165695), (93988, 4.659768774369048), (1307, 4.657703372161455), (318, 4.65542885669678), (2396, 4.654713440852059), (1250, 4.64881939346963), (93040, 4.634936313273813), (1939, 4.6204651732549475)], [(1196, 4.654159241967601), (260, 4.46005892981894), (4993, 4.426276826067508), (1210, 4.390476380513228), (7153, 4.373354928665624), (5952, 4.270301261813801), (58559, 4.153842999454238), (78499, 4.139977532842279), (27611, 4.124318872327237), (2571, 4.115371165659406), (95654, 3.98389007316059), (589, 3.958934460266847), (2700, 3.9375950205802286), (1270, 3.918569609362338), (1198, 3.9158942201374747), (1374, 3.8937286747174493), (2716, 3.8760689368074877), (2987, 3.8481286532824264), (1291, 3.8090481456843137), (1200, 3.773727245115719)], [(953, 4.680325906164749), (356, 4.612893441085176), (1035, 4.592685646245932), (72998, 4.550342481963721), (2324, 4.456273441768996), (93040, 4.441053341274162), (8533, 4.422624833426495), (920, 4.382983229418992), (1307, 4.366784103765409), (527, 4.366159251288956), (1721, 4.351122059298909), (1097, 4.343514963381242), (318, 4.3428848554883395), (72641, 4.309364237514306), (1207, 4.298362672584072), (2028, 4.286928578868274), (912, 4.276569889906434), (7669, 4.273811722702959), (899, 4.272509091299625), (457, 4.2663623164735585)], [(296, 4.552172181998032), (2959, 4.358362638489114), (50, 4.304900476907625), (108583, 4.259974775157765), (94466, 4.247548347286363), (2858, 4.236148449324215), (223, 4.214789834207137), (30803, 4.198559328372847), (4226, 4.197383757155278), (77658, 4.178151404033442), (44421, 4.173657399281356), (2997, 4.170824368372547), (62336, 4.1612071704901386), (4183, 4.158089489220992), (32657, 4.147792128211247), (1136, 4.137344467317719), (66934, 4.134756729909661), (5952, 4.128646437965052), (6016, 4.127075517378064), (778, 4.124634051891302)], [(6918, 4.82556855790762), (3089, 4.8242779301667795), (670, 4.767912304937571), (2351, 4.691253986996948), (4306, 4.684987145183198), (199, 4.673955858267998), (82143, 4.646022708099838), (745, 4.639036705604331), (1260, 4.637336918236561), (1256, 4.634574817179449), (1517, 4.628191811560749), (2791, 4.627877473106191), (904, 4.62111365382471), (1221, 4.61986628670693), (6669, 4.608806318281432), (5121, 4.594588686546537), (5932, 4.592121319868249), (52767, 4.586756003722041), (923, 4.586646935435111), (1923, 4.5854898737674334)], [(296, 4.957868425332245), (924, 4.83995244128033), (1206, 4.818529337776382), (4848, 4.800511385686055), (111, 4.700408087201847), (2076, 4.683292222089672), (923, 4.659803877294733), (1221, 4.622699082654153), (1251, 4.616242535063206), (750, 4.587383233089483), (1260, 4.553461656066141), (1209, 4.547110955788961), (501, 4.545647520033656), (858, 4.519557060261356), (108583, 4.503007783339168), (608, 4.497706345319449), (1208, 4.489758563393191), (77658, 4.47233339603948), (7063, 4.464990906342626), (1228, 4.4404434445529635)], [(858, 5), (296, 5), (1221, 4.972688649527622), (608, 4.889991982736493), (111, 4.850388252875149), (50, 4.820324193654325), (1193, 4.803279870279339), (1209, 4.796932491593654), (2959, 4.762873592508258), (55820, 4.75269171012376), (593, 4.7417965039287715), (1089, 4.740289219590997), (94466, 4.7144294434694665), (2997, 4.714241510746561), (4848, 4.708322726959882), (541, 4.705548658333368), (6016, 4.704977733343283), (3949, 4.703235784816877), (1208, 4.701181065366784), (4226, 4.698450609618694)], [(6187, 4.768979246838057), (92259, 4.635226010776663), (2324, 4.613026281596591), (33166, 4.59658760643685), (3275, 4.516029103626734), (1704, 4.494227284703972), (64034, 4.456888954205013), (82, 4.432812069542441), (7377, 4.431675866380939), (55247, 4.411490587885539), (4239, 4.402280330636526), (71033, 4.395888691066466), (2431, 4.387136433116952), (2106, 4.377911959612712), (3969, 4.370384455568473), (1246, 4.37007509157143), (1535, 4.356211610372509), (35, 4.355018597697308), (88810, 4.342986744205794), (9010, 4.336856397673664)], [(2324, 4.706976658291152), (527, 4.629631681073931), (318, 4.6211791674348595), (7153, 4.605160778486416), (1183, 4.583763201412472), (5952, 4.5794223966059615), (356, 4.573918522078504), (74458, 4.565156368004373), (77658, 4.557583106978461), (100553, 4.526710576762594), (4993, 4.501605145431662), (1704, 4.499595879790818), (96821, 4.497043996263354), (92259, 4.488823615006182), (3147, 4.480471699075314), (79132, 4.478283401495731), (4973, 4.4712172474254235), (5995, 4.470976765156167), (32649, 4.470016930241369), (50, 4.465144344826701)]]\n"
     ]
    }
   ],
   "source": [
    "n = 20\n",
    "top_n = []\n",
    "all_users = algo.trainset._raw2inner_id_users.keys()\n",
    "print(str(len(all_users)))\n",
    "all_items = algo.trainset._raw2inner_id_items.keys()\n",
    "\n",
    "top_n_start_time = datetime.datetime.now()\n",
    "for k, u in enumerate(all_users):\n",
    "    user_recommendations = []\n",
    "    for i in all_items:\n",
    "        prediction = algo.predict(u, i)\n",
    "        user_recommendations.append((prediction.iid, prediction.est))\n",
    "    user_recommendations.sort(key=lambda x: x[1], reverse=True)\n",
    "    top_n.append(user_recommendations[:n])\n",
    "    if k == 10: # Debug\n",
    "        break\n",
    "print(top_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
