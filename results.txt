Model fidelity:
- Recommender system trained using 75%/25% train-test split
- Association rules were calculated with max. antecedent length of 3, consequent length of 1, min. support of 0.005 and min. confidence of 0.3
- To avoid computationally expensive operations, a 1% sample of all users (sampled using the modulus operator in natural user ordering) was used. This was done using global association rules only. For top-n calculation, movies users had rated before were allowed.

Results:
    n=20: 0.15422382671480145 (~15.4%) (redo!)
    n=30: (Peake, Wang): ?
    n=40: ?

MF-model
- Model was trained using the MovieLense 20m set of ratings. The data was first split with a 75%/25% train-test split. Training set was then used for cross-vadidation with 4 splits. Hyperparameters n_factors and n_epochs were optimised separately:

n_epochs (RMSE, MAE)
1: (0.8924, 0.6885)
2: (0.8791, 0.6778)
5: (0.8583, 0.6602)
10: (0.8288, 0.6347)
20: (0.8056, 0.6141)
35: (0.8087, 0.6150)
50: (0.8158, 0.6200)


- Model with n_factors = 100: 0.7894
- Model with n_factors = 50: 0.7896
- Model with n_factors = 10: 0.7971



